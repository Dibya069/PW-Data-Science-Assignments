{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c388cb9b",
   "metadata": {},
   "source": [
    "# Q1. How does bagging reduce overfitting in decision trees?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dbf090",
   "metadata": {},
   "source": [
    "Bagging reduces overfitting in decision trees by introducing randomness in two ways - by **randomly selecting subsets of the training data**, and by **randomly selecting subsets of features at each split in the decision tree**. This randomness helps to decorrelate the trees and increase the diversity of the ensemble, which in turn reduces the variance and improves the generalization performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaafbe0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e47f593e",
   "metadata": {},
   "source": [
    "# Q2. What are the advantages and disadvantages of using different types of base learners in bagging?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9781db",
   "metadata": {},
   "source": [
    "1. Decision Trees:<br>\n",
    "\n",
    "Advantages:\n",
    "- Decision trees are simple and easy to understand, which can make them a good choice as base learners in bagging.\n",
    "- They are highly interpretable and can be used to identify the most important features in the data.\n",
    "- They can handle both categorical and numerical data, and are not sensitive to outliers.<br>\n",
    "\n",
    "Disadvantages:\n",
    "- Decision trees have a tendency to overfit, which can limit their performance in bagging.\n",
    "- They can be sensitive to small changes in the data, which can lead to instability in the ensemble.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e41c09",
   "metadata": {},
   "source": [
    "2. Support Vector Machines (SVMs):<br>\n",
    "\n",
    "Advantages:\n",
    "- SVMs are known for their high accuracy and ability to handle complex data distributions, which can make them a good choice as base learners in bagging.\n",
    "- They have a strong theoretical foundation and are well-suited for classification tasks.<br>\n",
    "\n",
    "Disadvantages:\n",
    "- SVMs can be computationally expensive, which can make them impractical for very large datasets.\n",
    "- They are not as interpretable as decision trees and can be difficult to understand and visualize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165108c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "527eccca",
   "metadata": {},
   "source": [
    "# Q3. How does the choice of base learner affect the bias-variance tradeoff in bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a5f5d9",
   "metadata": {},
   "source": [
    "Low-bias models tend to benefit more from bagging, while high-variance models can also benefit if they are not too complex. Additionally, if the base learners are highly correlated, the variance reduction from bagging may be limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e88ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f519505",
   "metadata": {},
   "source": [
    "# Q4. Can bagging be used for both classification and regression tasks? How does it differ in each case?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d7a1c9",
   "metadata": {},
   "source": [
    " Yes Bagging can be used for both Classification and Regression tasks.\n",
    "    \n",
    " - In case of Classification we use majority voting method to get the output.\n",
    " - In case of Regression we use average mean method to get the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7a574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96f5200d",
   "metadata": {},
   "source": [
    "# Q5. What is the role of ensemble size in bagging? How many models should be included in the ensemble?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736bd19a",
   "metadata": {},
   "source": [
    "- The ensemble size in bagging refers to the number of base models that are included in the ensemble. \n",
    "\n",
    "- There is no fixed answer to how many models should be included in the ensemble. It is important to experiment with different ensemble sizes and evaluate the performance on a validation set to find the optimal ensemble size for the specific problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129f4673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b88a5a9a",
   "metadata": {},
   "source": [
    "# Q6. Can you provide an example of a real-world application of bagging in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49256e93",
   "metadata": {},
   "source": [
    "- Real-world application of bagging in machine learning is in the field of medical diagnosis.\n",
    "\n",
    "- For example, bagging has been used to develop ensemble models for breast cancer diagnosis based on features extracted from medical images. By combining the predictions of multiple classifiers, bagging can help to improve the accuracy and reliability of the diagnosis, reducing the number of false positives and false negatives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c31962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
