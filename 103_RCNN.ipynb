{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db5150d-64ae-49e7-8d29-f24b7ac9b6d7",
   "metadata": {},
   "source": [
    "## 1. What are the objective of using Selective Search in R-CNN ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1317e2-8833-4a0f-89b2-400d2c9a2b4f",
   "metadata": {},
   "source": [
    "- Selective Search is used as a region proposal method in R-CNN (Region-based Convolutional Neural Network) to generate potential regions of interest (ROIs) in an input image.\n",
    "- The objective of using Selective Search in R-CNN is to efficiently propose a diverse set of regions that likely contain objects, helping to focus subsequent computational efforts on the most promising areas of the image. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6e0bc2-544b-4210-b243-d0d3f557552c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a049de52-a35d-4399-a335-0469526269e1",
   "metadata": {},
   "source": [
    "## 2. Explain the following phases involved in R-CNN:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66782b9f-68aa-4648-b44d-4a208a326662",
   "metadata": {},
   "source": [
    "###    a. Region Proposal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d47e26a-55cc-41f9-a593-1f3440ef6bcb",
   "metadata": {},
   "source": [
    "`In the region proposal phase, potential regions of interest (ROIs) are generated from the input image. These regions are proposed based on selective search or another region proposal method. The goal is to identify candidate regions that may contain objects.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0e906a-713a-4525-a62b-0fba81f17ef3",
   "metadata": {},
   "source": [
    "###    b. Warping and resizing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516ceca1-dbc4-4ce3-bf25-7e2adbb035e0",
   "metadata": {},
   "source": [
    "`The purpose of warping and resizing is to make the regions compatible with the input size expected by the subsequent neural network layers.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f094f7-93a2-4dfe-a90c-c3f68d014c71",
   "metadata": {},
   "source": [
    "###    c. Pre trained CNN architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab5dd8-2a3a-4023-813a-ff441fbac8ad",
   "metadata": {},
   "source": [
    "`The regions of interest, now warped and resized, are passed through a pre-trained CNN (Convolutional Neural Network) architecture. The CNN serves as a feature extractor, capturing relevant features from the proposed regions.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9891680-667d-4639-a7d2-bd468c4c797a",
   "metadata": {},
   "source": [
    "###    d. Pre trained SVM models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd335fb-1342-4722-8181-128f8067cdbe",
   "metadata": {},
   "source": [
    "`Following the CNN feature extraction, a support vector machine (SVM) is trained for each object class. These SVM models are used to classify the extracted features into different classes, determining whether a given region contains an object of interest or not. `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555b9b1e-e697-4b03-834e-f40c94cea1cb",
   "metadata": {},
   "source": [
    "###    e. Clean up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3dbd72-a9a1-433e-9afe-e92da720e2ff",
   "metadata": {},
   "source": [
    "`After classification, a post-processing step is performed to eliminate duplicate or highly overlapping bounding box proposals. Non-maximum suppression (NMS) is commonly used to clean up the bounding box proposals, keeping only the most confident predictions.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddb1c74-19db-454c-b27a-cfa5e212ba75",
   "metadata": {},
   "source": [
    "###    f. Implementation of bounding box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daa179a-be70-4cd3-9061-825405f5b459",
   "metadata": {},
   "source": [
    "`The final step involves implementing bounding boxes around the detected objects based on the refined region proposals and their classifications. `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d709086-cba2-43c8-b550-ac0252e6c698",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. What are the possible pre trained CNNs we can use in Pre trained CNN Architecrure ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- VGG (Visual Geometry Group) Networks: VGG16, VGG19\n",
    "- Residual Network (ResNet): ResNet50, ResNet101, ResNet152\n",
    "- GoogLeNet (Inception): InceptionV3\n",
    "- Xception: Xception\n",
    "- DenseNet: DenseNet121, DenseNet169, DenseNet201\n",
    "- AlexNet: AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. How is SVM implemented in the R-CNN framework ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The region proposals are warped and resized to a fixed size, usually to match the input size expected by a pre-trained Convolutional Neural Network (CNN).\n",
    "- The warped and resized region proposals are fed through a pre-trained CNN, such as VGG, ResNet, or another architecture. \n",
    "- For each class, a separate SVM is trained using the features extracted by the pre-trained CNN. These SVMs are binary classifiers that determine whether a given region proposal belongs to a particular object class or not.\n",
    "\n",
    "- The combination of region proposal, feature extraction using a pre-trained CNN, and classification using **SVMs** allows the R-CNN framework to detect and classify objects in images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. How does Non-maximum Supression work ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sort all the bounding box proposals in descending order based on their confidence scores. The proposal with the highest confidence score comes first.\n",
    "- Start with the bounding box proposal that has the highest confidence score. \n",
    "- Calculate the Intersection over Union (IoU) between the candidate box and all other remaining boxes in the sorted list. IoU is a measure of the overlap between two bounding boxes and is calculated as the area of intersection divided by the area of the union.\n",
    "- Set a predefined IoU threshold (e.g., 0.5). If the IoU between the candidate box and any other box exceeds this threshold, discard the box with the lower confidence score.\n",
    "- Repeat the process by selecting the next highest-scoring box from the sorted list and calculating IoU with the remaining boxes. Again, discard any boxes that exceed the IoU threshold.\n",
    "- Continue this process until all boxes in the sorted list have been considered.\n",
    "- **This cleaning process is called Non-maximum Supression work**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. How Fast R-CNN is better than R-CNN ??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- R-CNN used a separate algorithm (Selective Search) for region proposals, which was slow and a bottleneck in the system. Fast R-CNN, on the other hand, incorporates the region proposal step into the neural network itself, making it an end-to-end trainable system.\n",
    "- In R-CNN, each region proposal was independently processed by a CNN, resulting in redundant computations for overlapping regions. Fast R-CNN shares the computation for overlapping regions, making the process more efficient.\n",
    "- R-CNN extracts features separately for each region proposal, leading to redundant feature computation. In Fast R-CNN, features are extracted only once for the entire image, and the region of interest (ROI) pooling layer is used to obtain fixed-size feature vectors for each region proposal. \n",
    "- Fast R-CNN allows end-to-end training of the entire system, including the region proposal network (RPN) and the object detection network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using mathematical intuition, explain ROI polling in Fast R-CNN ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROI (Region of Interest) pooling is a crucial step in Fast R-CNN that allows the extraction of a fixed-size feature vector from an arbitrary-sized region of the feature map.\n",
    "- Suppose we have a feature map of size `W × H × C (width, height, channels)`.\n",
    "- For a given region proposal, represented by the coordinates `(x,y,w,h)`, where `(x,y)` is the top-left corner, w and h are the width and height, respectively.\n",
    "- Divide the region proposal into a fixed grid. Each grid cell corresponds to a fraction of the original region. Apply max pooling independently in each grid cell.The result is a fixed-size feature map for the region proposal.\n",
    "\n",
    "`ROI pooling=MaxPool({Feature map(x \n",
    "i\n",
    "​\n",
    " ,y \n",
    "i\n",
    "​\n",
    " )∣i=1,2,...,N})`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Explain Following Process..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. ROI Projection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROI projection refers to the mapping of a region proposal from the original image space to the feature map space. \n",
    "- In Fast R-CNN, this is essential because the region proposals are generated based on the original image, but the subsequent object detection is performed on a feature map.\n",
    "- Mathematically, ROI projection involves scaling and mapping the coordinates of the region proposal (x,y,w,h) from the original image space to the corresponding coordinates in the feature map space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. ROI polling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROI pooling is a process in Fast R-CNN that extracts fixed-size feature maps from the feature map corresponding to a region proposal. \n",
    "- This is necessary because region proposals can be of different sizes, and the subsequent fully connected layers require a consistent input size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
