{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db5150d-64ae-49e7-8d29-f24b7ac9b6d7",
   "metadata": {},
   "source": [
    "## 1. What are the objective of using Selective Search in R-CNN ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1317e2-8833-4a0f-89b2-400d2c9a2b4f",
   "metadata": {},
   "source": [
    "- Selective Search is used as a region proposal method in R-CNN (Region-based Convolutional Neural Network) to generate potential regions of interest (ROIs) in an input image.\n",
    "- The objective of using Selective Search in R-CNN is to efficiently propose a diverse set of regions that likely contain objects, helping to focus subsequent computational efforts on the most promising areas of the image. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6e0bc2-544b-4210-b243-d0d3f557552c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a049de52-a35d-4399-a335-0469526269e1",
   "metadata": {},
   "source": [
    "## 2. Explain the following phases involved in R-CNN:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66782b9f-68aa-4648-b44d-4a208a326662",
   "metadata": {},
   "source": [
    "###    a. Region Proposal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d47e26a-55cc-41f9-a593-1f3440ef6bcb",
   "metadata": {},
   "source": [
    "`In the region proposal phase, potential regions of interest (ROIs) are generated from the input image. These regions are proposed based on selective search or another region proposal method. The goal is to identify candidate regions that may contain objects.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0e906a-713a-4525-a62b-0fba81f17ef3",
   "metadata": {},
   "source": [
    "###    b. Warping and resizing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516ceca1-dbc4-4ce3-bf25-7e2adbb035e0",
   "metadata": {},
   "source": [
    "`The purpose of warping and resizing is to make the regions compatible with the input size expected by the subsequent neural network layers.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f094f7-93a2-4dfe-a90c-c3f68d014c71",
   "metadata": {},
   "source": [
    "###    c. Pre trained CNN architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab5dd8-2a3a-4023-813a-ff441fbac8ad",
   "metadata": {},
   "source": [
    "`The regions of interest, now warped and resized, are passed through a pre-trained CNN (Convolutional Neural Network) architecture. The CNN serves as a feature extractor, capturing relevant features from the proposed regions.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9891680-667d-4639-a7d2-bd468c4c797a",
   "metadata": {},
   "source": [
    "###    d. Pre trained SVM models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd335fb-1342-4722-8181-128f8067cdbe",
   "metadata": {},
   "source": [
    "`Following the CNN feature extraction, a support vector machine (SVM) is trained for each object class. These SVM models are used to classify the extracted features into different classes, determining whether a given region contains an object of interest or not. `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555b9b1e-e697-4b03-834e-f40c94cea1cb",
   "metadata": {},
   "source": [
    "###    e. Clean up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3dbd72-a9a1-433e-9afe-e92da720e2ff",
   "metadata": {},
   "source": [
    "`After classification, a post-processing step is performed to eliminate duplicate or highly overlapping bounding box proposals. Non-maximum suppression (NMS) is commonly used to clean up the bounding box proposals, keeping only the most confident predictions.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddb1c74-19db-454c-b27a-cfa5e212ba75",
   "metadata": {},
   "source": [
    "###    f. Implementation of bounding box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daa179a-be70-4cd3-9061-825405f5b459",
   "metadata": {},
   "source": [
    "`The final step involves implementing bounding boxes around the detected objects based on the refined region proposals and their classifications. `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d709086-cba2-43c8-b550-ac0252e6c698",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. What are the possible pre trained CNNs we can use in Pre trained CNN Architecrure ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- VGG (Visual Geometry Group) Networks: VGG16, VGG19\n",
    "- Residual Network (ResNet): ResNet50, ResNet101, ResNet152\n",
    "- GoogLeNet (Inception): InceptionV3\n",
    "- Xception: Xception\n",
    "- DenseNet: DenseNet121, DenseNet169, DenseNet201\n",
    "- AlexNet: AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. How is SVM implemented in the R-CNN framework ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The region proposals are warped and resized to a fixed size, usually to match the input size expected by a pre-trained Convolutional Neural Network (CNN).\n",
    "- The warped and resized region proposals are fed through a pre-trained CNN, such as VGG, ResNet, or another architecture. \n",
    "- For each class, a separate SVM is trained using the features extracted by the pre-trained CNN. These SVMs are binary classifiers that determine whether a given region proposal belongs to a particular object class or not.\n",
    "\n",
    "- The combination of region proposal, feature extraction using a pre-trained CNN, and classification using **SVMs** allows the R-CNN framework to detect and classify objects in images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. How does Non-maximum Supression work ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sort all the bounding box proposals in descending order based on their confidence scores. The proposal with the highest confidence score comes first.\n",
    "- Start with the bounding box proposal that has the highest confidence score. \n",
    "- Calculate the Intersection over Union (IoU) between the candidate box and all other remaining boxes in the sorted list. IoU is a measure of the overlap between two bounding boxes and is calculated as the area of intersection divided by the area of the union.\n",
    "- Set a predefined IoU threshold (e.g., 0.5). If the IoU between the candidate box and any other box exceeds this threshold, discard the box with the lower confidence score.\n",
    "- Repeat the process by selecting the next highest-scoring box from the sorted list and calculating IoU with the remaining boxes. Again, discard any boxes that exceed the IoU threshold.\n",
    "- Continue this process until all boxes in the sorted list have been considered.\n",
    "- **This cleaning process is called Non-maximum Supression work**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. How Fast R-CNN is better than R-CNN ??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- R-CNN used a separate algorithm (Selective Search) for region proposals, which was slow and a bottleneck in the system. Fast R-CNN, on the other hand, incorporates the region proposal step into the neural network itself, making it an end-to-end trainable system.\n",
    "- In R-CNN, each region proposal was independently processed by a CNN, resulting in redundant computations for overlapping regions. Fast R-CNN shares the computation for overlapping regions, making the process more efficient.\n",
    "- R-CNN extracts features separately for each region proposal, leading to redundant feature computation. In Fast R-CNN, features are extracted only once for the entire image, and the region of interest (ROI) pooling layer is used to obtain fixed-size feature vectors for each region proposal. \n",
    "- Fast R-CNN allows end-to-end training of the entire system, including the region proposal network (RPN) and the object detection network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using mathematical intuition, explain ROI polling in Fast R-CNN ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROI (Region of Interest) pooling is a crucial step in Fast R-CNN that allows the extraction of a fixed-size feature vector from an arbitrary-sized region of the feature map.\n",
    "- Suppose we have a feature map of size `W × H × C (width, height, channels)`.\n",
    "- For a given region proposal, represented by the coordinates `(x,y,w,h)`, where `(x,y)` is the top-left corner, w and h are the width and height, respectively.\n",
    "- Divide the region proposal into a fixed grid. Each grid cell corresponds to a fraction of the original region. Apply max pooling independently in each grid cell.The result is a fixed-size feature map for the region proposal.\n",
    "\n",
    "`ROI pooling=MaxPool({Feature map(x \n",
    "i\n",
    "​\n",
    " ,y \n",
    "i\n",
    "​\n",
    " )∣i=1,2,...,N})`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Explain Following Process..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. ROI Projection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROI projection refers to the mapping of a region proposal from the original image space to the feature map space. \n",
    "- In Fast R-CNN, this is essential because the region proposals are generated based on the original image, but the subsequent object detection is performed on a feature map.\n",
    "- Mathematically, ROI projection involves scaling and mapping the coordinates of the region proposal (x,y,w,h) from the original image space to the corresponding coordinates in the feature map space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. ROI polling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROI pooling is a process in Fast R-CNN that extracts fixed-size feature maps from the feature map corresponding to a region proposal. \n",
    "- This is necessary because region proposals can be of different sizes, and the subsequent fully connected layers require a consistent input size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. In comparison with R-CNN, why did the object classifier activate function change in Fast R-CNN ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In R-CNN, the object classifier used softmax activation for object classification. However, in Fast R-CNN, the softmax activation was replaced with a softmax function applied independently for each class, combined with a binary sigmoid activation for the background class.\n",
    "\n",
    "- Multi-Class Classification within Regions:\n",
    "  `In R-CNN, each region proposal was classified independently into one of the classes using a softmax activation. This approach didn't consider the fact that an object might belong to multiple classes simultaneously.`\n",
    "\n",
    "- Binary Background Class Activation:\n",
    "  `Fast R-CNN introduced a binary sigmoid activation for the background class. This allows the model to distinguish between the object classes and the background, treating background as a separate class.`\n",
    "\n",
    "- Efficiency and Training Simplicity:\n",
    "  `The change in the activation function simplifies the training process. It allows for more flexibility in handling multi-class scenarios and improves the efficiency of the training process.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. What major changes in Faster R-CNN compared to Fast R-CNN ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faster R-CNN is an extension of Fast R-CNN that introduces a Region Proposal Network (RPN) to generate region proposals, eliminating the need for an external region proposal method like Selective Search.\n",
    "\n",
    "- Region Proposal Network (RPN):\n",
    "  `The most significant change is the integration of the Region Proposal Network (RPN) into the overall architecture. The RPN generates region proposals based on anchor boxes and is trained simultaneously with the object detection network.`\n",
    "\n",
    "- End-to-End Training:\n",
    "  `Faster R-CNN enables end-to-end training of both the RPN and the object detection network. This unified training approach leads to better optimization and improved overall performance.`\n",
    "\n",
    "- Anchor Boxes:\n",
    "  `Faster R-CNN uses anchor boxes (also called anchor boxes or default boxes) in the RPN to propose potential regions of interest. These anchor boxes are pre-defined bounding boxes of different scales and aspect ratios. The RPN predicts adjustments to these anchor boxes to refine the proposals.`\n",
    "\n",
    "- Shared Convolutional Features:\n",
    "  `The convolutional features are shared between the RPN and the object detection network, reducing redundancy and computational cost.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Explain the concept of Anchore box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Anchor boxes, also known as anchor boxes or default boxes, are a crucial concept in object detection models like Faster R-CNN. They are used by the Region Proposal Network (RPN) to generate potential bounding box proposals.\n",
    "- The use of anchor boxes contributes to the efficiency and accuracy of the region proposal process in object detection models like Faster R-CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Implementation of Fast R-CNN using 2017 COCO dataset i.e train dataset, test dataset and valid dataset. Use pre-trained backbone network like, Resnet or VGG for feature extraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.13.1-cp38-cp38-win_amd64.whl.metadata (2.6 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached tensorflow-2.13.0-cp38-cp38-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting tensorflow-intel==2.13.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.13.0-cp38-cp38-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.0.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=2.9.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached h5py-3.10.0-cp38-cp38-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.23.5)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached protobuf-4.25.1-cp38-cp38-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached wrapt-1.16.0-cp38-cp38-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.59.0)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (6.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\mohan\\anaconda3\\envs\\vcount\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Using cached tensorflow-2.13.0-cp38-cp38-win_amd64.whl (1.9 kB)\n",
      "Using cached tensorflow_intel-2.13.0-cp38-cp38-win_amd64.whl (276.5 MB)\n",
      "Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Using cached h5py-3.10.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Using cached libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Using cached protobuf-4.25.1-cp38-cp38-win_amd64.whl (413 kB)\n",
      "Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "Using cached wrapt-1.16.0-cp38-cp38-win_amd64.whl (37 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, protobuf, opt-einsum, keras, h5py, google-pasta, gast, astunparse, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.8.0\n",
      "    Uninstalling typing_extensions-4.8.0:\n",
      "      Successfully uninstalled typing_extensions-4.8.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.2\n",
      "    Uninstalling protobuf-4.21.2:\n",
      "      Successfully uninstalled protobuf-4.21.2\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.14.0\n",
      "    Uninstalling tensorboard-2.14.0:\n",
      "      Successfully uninstalled tensorboard-2.14.0\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-23.5.26 gast-0.4.0 google-pasta-0.2.0 h5py-3.10.0 keras-2.13.1 libclang-16.0.6 opt-einsum-3.3.0 protobuf-4.25.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-intel-2.13.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 typing-extensions-4.5.0 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
