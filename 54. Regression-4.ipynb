{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9321f11",
   "metadata": {},
   "source": [
    "## Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d580c44",
   "metadata": {},
   "source": [
    "- Lasso Regression, also known as L1 regularization, is a regression technique that adds a penalty term to the ordinary least squares objective function. This penalty term is the L1 norm of the coefficient vector multiplied by a regularization parameter (lambda).\n",
    "- Lasso Regression encourages sparsity in the model by shrinking some coefficients to exactly zero, effectively performing feature selection. This distinguishes it from other regression techniques like Ridge Regression, which only shrinks the coefficients towards zero without setting them exactly to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eae56e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32502c3a",
   "metadata": {},
   "source": [
    "## Q2. What is the main advantage of using Lasso Regression in feature selection?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc3fc84",
   "metadata": {},
   "source": [
    "The main advantage of using Lasso Regression in feature selection is its ability to automatically select relevant features by setting the coefficients of irrelevant features to zero. This is particularly useful when dealing with high-dimensional data or when there are a large number of potentially irrelevant predictors. By eliminating irrelevant features, Lasso Regression helps to simplify the model and improve interpretability, reducing the risk of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2007128d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff6242d",
   "metadata": {},
   "source": [
    "## Q3. How do you interpret the coefficients of a Lasso Regression model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0ce01d",
   "metadata": {},
   "source": [
    "- In Lasso Regression, the interpretation of coefficients is similar to that of other regression techniques. A positive coefficient indicates a positive relationship between the predictor variable and the response variable, while a negative coefficient indicates a negative relationship. The magnitude of the coefficient reflects the strength of the relationship, where larger coefficients imply a larger impact on the response variable. However, it's important to note that when Lasso Regression introduces sparsity, some coefficients may be exactly zero, indicating that the corresponding features have been excluded from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f743d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f57f0d",
   "metadata": {},
   "source": [
    "## Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746ca92d",
   "metadata": {},
   "source": [
    "- The main tuning parameter in Lasso Regression is the regularization parameter, often denoted as lambda. Lambda controls the strength of the regularization penalty applied to the coefficients. A larger lambda value leads to stronger regularization and a greater tendency to shrink coefficients towards zero or eliminate them entirely. The choice of lambda determines the trade-off between model complexity and the model's ability to fit the training data. It can be determined using techniques such as cross-validation, where different values of lambda are evaluated on subsets of the data to find the optimal balance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df258bcc",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817e4847",
   "metadata": {},
   "source": [
    "## Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68605f79",
   "metadata": {},
   "source": [
    "- Lasso Regression can handle non-linear regression problems indirectly by using polynomial features or basis functions. By transforming the original features into higher-order polynomial features or applying non-linear transformations, Lasso Regression can capture non-linear relationships between predictors and the response variable. This approach extends the model's flexibility and enables it to fit non-linear patterns in the data. However, it's important to note that Lasso Regression itself is a linear model in terms of the relationship between predictors and coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a28c931",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f83b2d",
   "metadata": {},
   "source": [
    "## Q6. What is the difference between Ridge Regression and Lasso Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714fdccd",
   "metadata": {},
   "source": [
    "- The main difference between Ridge Regression and Lasso Regression lies in the type of regularization used. Ridge Regression uses L2 regularization, which adds the L2 norm of the coefficient vector to the objective function, while Lasso Regression uses L1 regularization, which adds the L1 norm of the coefficient vector. This difference results in distinct behaviors: Ridge Regression shrinks the coefficients towards zero without setting them exactly to zero, while Lasso Regression can set coefficients exactly to zero, effectively performing feature selection. Consequently, Lasso Regression is more suitable for situations where feature selection is desired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d24e67",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec762f3",
   "metadata": {},
   "source": [
    "## Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c53ed4c",
   "metadata": {},
   "source": [
    "- Yes, Lasso Regression can handle multicollinearity in the input features. Multicollinearity occurs when predictor variables are highly correlated with each other. In the presence of multicollinearity, Lasso Regression tends to select only one of the correlated features while setting the coefficients of the others to zero. This behavior is a consequence of the L1 regularization term, which encourages sparsity and feature selection. By setting redundant coefficients to zero, Lasso Regression effectively deals with multicollinearity and simplifies the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d651cb61",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c99fd",
   "metadata": {},
   "source": [
    "## Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd686df",
   "metadata": {},
   "source": [
    "-  The optimal value of the regularization parameter lambda in Lasso Regression can be chosen using techniques such as cross-validation. Cross-validation involves evaluating the performance of the model on different subsets of the data for different lambda values. The goal is to find the lambda value that achieves the best trade-off between model complexity and generalization performance. Techniques like grid search or randomized search can be used to explore a range of lambda values and select the one that yields the best performance based on a chosen evaluation metric, such as mean squared error or R-squared.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6443aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
