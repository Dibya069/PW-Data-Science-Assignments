{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27cc31e8",
   "metadata": {},
   "source": [
    "# Q1. What is the purpose of grid search cv in machine learning, and how does it work?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d41c99f",
   "metadata": {},
   "source": [
    "- For doing Hypertuning we need to use Grid search CV. It is used to find the best combination of hyperparameters for a given model by exhaustively searching through a pre-defined set of hyperparameters.\n",
    "- Grid search CV works by specifying a grid of hyperparameters and evaluating the performance of the model using cross-validation. The grid search algorithm evaluates all possible combinations of hyperparameters in the specified grid and returns the combination with the best cross-validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9b3a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e9f1af3",
   "metadata": {},
   "source": [
    "# Q2. Describe the difference between grid search cv and randomize search cv, and when might you choose one over the other?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbdc964",
   "metadata": {},
   "source": [
    "Grid search CV involves exhaustively searching over a pre-defined grid of hyperparameters, where each combination of hyperparameters is evaluated using cross-validation. This can be a computationally expensive process, as the search space grows exponentially with the number of hyperparameters and their possible values.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Randomized search CV, on the other hand, randomly samples from a distribution of hyperparameters to create a set of hyperparameter configurations, which are then evaluated using cross-validation. This approach is less computationally expensive than grid search CV, as it does not exhaustively search over the entire hyperparameter space. However, it may require more iterations to find the best hyperparameters, as some promising regions of the hyperparameter space may be missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875bca04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f508aca",
   "metadata": {},
   "source": [
    "# Q3. What is data leakage, and why is it a problem in machine learning? Provide an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5585ff73",
   "metadata": {},
   "source": [
    " - This topic is not cover yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8393c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcd7af28",
   "metadata": {},
   "source": [
    "# Q4. How can you prevent data leakage when building a machine learning model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa2926",
   "metadata": {},
   "source": [
    "- Not cover yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85460d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb044d62",
   "metadata": {},
   "source": [
    "# Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d06f767",
   "metadata": {},
   "source": [
    "A confusion matrix is a table used to evaluate the performance of a classification model. It shows the number of correct and incorrect predictions made by the model, by comparing the predicted labels with the actual labels. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The confusion matrix provides several metrics that can be used to evaluate the performance of a classification model, including:\n",
    "- Accuracy: the proportion of correctly classified samples, computed as (TP + TN) / (TP + TN + FP + FN)\n",
    "- Precision: the proportion of true positive predictions among all positive predictions, computed as TP / (TP + FP)\n",
    "- Recall (also known as sensitivity or true positive rate): the proportion of true positive predictions among all actual positive samples, computed as TP / (TP + FN)\n",
    "- F1-score: the harmonic mean of precision and recall, computed as 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4f94ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4562bf9a",
   "metadata": {},
   "source": [
    "# Q6. Explain the difference between precision and recall in the context of a confusion matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be18f32b",
   "metadata": {},
   "source": [
    "Precision :\n",
    "- TP / (TP + FP)\n",
    "-  A high precision indicates that the model has a low false positive rate, and is making accurate positive predictions.\n",
    "<br><br>\n",
    "\n",
    "\n",
    "Recall:\n",
    "- TP / (TP + FN)\n",
    "-  A high recall indicates that the model has a low false negative rate, and is able to identify most of the positive samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538fa946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "514bf6c5",
   "metadata": {},
   "source": [
    "# Q7. How can you interpret a confusion matrix to determine which types of errors your model is making?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01751fd",
   "metadata": {},
   "source": [
    "- Look for patterns in the errors made by the model. For example, if the model is making a large number of false positives, it may be overly sensitive to certain features or may have a low threshold for predicting the positive class. On the other hand, if the model is making a large number of false negatives, it may be missing important features or may have a high threshold for predicting the positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cade1f85",
   "metadata": {},
   "source": [
    "- Analyze the precision and recall of the model. Precision is computed as TP / (TP + FP), while recall is computed as TP / (TP + FN). A low precision indicates that the model is making a large number of false positive predictions, while a low recall indicates that the model is missing a large number of positive samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e5401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9125da9d",
   "metadata": {},
   "source": [
    "# Q8. What are some common metrics that can be derived from a confusion matrix, and how are theycalculated?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc2f51c",
   "metadata": {},
   "source": [
    "1. Accuracy: (TP + TN) / (TP + TN + FP + FN)\n",
    "2. Precision: TP / (TP + FP)\n",
    "3. Recall: TP / (TP + FN)\n",
    "4. F1 Score: 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb90729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c34ff8c",
   "metadata": {},
   "source": [
    "# Q9. What is the relationship between the accuracy of a model and the values in its confusion matrix?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeac06cd",
   "metadata": {},
   "source": [
    "Accuracy of a model is positively correlated with the number of correct predictions (true positives and true negatives) and negatively correlated with the number of incorrect predictions (false positives and false negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265b282c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae899380",
   "metadata": {},
   "source": [
    "# Q10. How can you use a confusion matrix to identify potential biases or limitations in your machine learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ee0ca3",
   "metadata": {},
   "source": [
    "- Class imbalance: If the confusion matrix reveals a large difference in the number of samples between the positive and negative classes, it suggests that the dataset may be imbalanced. This can lead to biases in the model's predictions, as it may be more likely to predict the majority class. <br><br>\n",
    "\n",
    "- False positive or false negative biases: If the model is making a large number of false positive or false negative predictions, it may suggest that there are biases in the data or that the model is overfitting to certain features. For example, if a model is trained on data that is biased towards a particular demographic group, it may be more likely to make false positive or false negative predictions for samples from that group.<br><br>\n",
    "\n",
    "- Limited feature representation: If the confusion matrix shows a high number of misclassifications for a particular class, it may suggest that the features used to train the model are not representative of that class. This could be due to a lack of data or a failure to capture important features.<br><br>\n",
    "\n",
    "- Confusing similar classes: If the confusion matrix shows that the model is making a large number of misclassifications between similar classes, it may suggest that the features used to train the model are not sufficient to distinguish between those classes. In this case, it may be necessary to incorporate additional features or adjust the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aeacb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
